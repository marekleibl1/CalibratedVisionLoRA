{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8c4239e-5822-49d6-9ad1-0db38e44cdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook is intended to show the full pipeline and test that everything works. \n",
    "\n",
    "Note that when running for the first time, it might take a while to download the training data. \n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os \n",
    "from os.path import join\n",
    "import math\n",
    "import sys\n",
    "import numpy as np \n",
    "\n",
    "sys.path.append('../calibratedvisionlora')\n",
    "\n",
    "from utils import print_trainable_parameters\n",
    "from dataloaders import create_food_data_loaders\n",
    "from training import train_single_model\n",
    "from calibration import fit_laplace_and_compute_predictions, eval_metrics\n",
    "\n",
    "config = dict(\n",
    "    model_name = 'sample_lora_model',\n",
    "    n_classes = 5,\n",
    "    batch_size =  32,  # Make it smaller if running out of memory\n",
    "    lora_rank = 1,                \n",
    "    lora_layers = [10, 11],\n",
    "    random_projections=False,\n",
    "    learning_rate =  0.001,\n",
    "    epochs =  3,\n",
    "    train_model = True \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56c71599-014f-4a6f-aa34-97f6febb2d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Model Training ...\n",
      "{'model_name': 'sample_lora_model', 'n_classes': 5, 'batch_size': 32, 'lora_rank': 1, 'lora_layers': [10, 11], 'random_projections': False, 'learning_rate': 0.001, 'epochs': 3, 'train_model': True}\n",
      "Loaded pretrained weights.\n",
      "Total number of parameters: 86100485\n",
      "Number of trainable parameters: 9989\n",
      "Trainable parameters per layer:\n",
      " 9989\n",
      "lora_vit 9989\n",
      "lora_vit.transformer 6144\n",
      "lora_vit.transformer.blocks 6144\n",
      "lora_vit.transformer.blocks.10 3072\n",
      "lora_vit.transformer.blocks.10.attn 3072\n",
      "lora_vit.transformer.blocks.10.attn.proj_q 1536\n",
      "lora_vit.transformer.blocks.10.attn.proj_q.w_a 768\n",
      "lora_vit.transformer.blocks.10.attn.proj_q.w_b 768\n",
      "lora_vit.transformer.blocks.10.attn.proj_v 1536\n",
      "lora_vit.transformer.blocks.10.attn.proj_v.w_a 768\n",
      "lora_vit.transformer.blocks.10.attn.proj_v.w_b 768\n",
      "lora_vit.transformer.blocks.11 3072\n",
      "lora_vit.transformer.blocks.11.attn 3072\n",
      "lora_vit.transformer.blocks.11.attn.proj_q 1536\n",
      "lora_vit.transformer.blocks.11.attn.proj_q.w_a 768\n",
      "lora_vit.transformer.blocks.11.attn.proj_q.w_b 768\n",
      "lora_vit.transformer.blocks.11.attn.proj_v 1536\n",
      "lora_vit.transformer.blocks.11.attn.proj_v.w_a 768\n",
      "lora_vit.transformer.blocks.11.attn.proj_v.w_b 768\n",
      "lora_vit.fc 3845\n",
      "Training Samples - Train 1024 Test 512\n",
      "Batch size: 32\n",
      "device cuda:0\n",
      "[1, 32] loss: 1.232\n",
      "Epoch 1, Test loss: 0.985, Test accuracy: 0.475\n",
      "Model exported to ../models/sample_lora_model.pth\n",
      "[2, 32] loss: 0.991\n",
      "[3, 32] loss: 0.925\n",
      "Epoch 3, Test loss: 0.921, Test accuracy: 0.479\n",
      "Model exported to ../models/sample_lora_model.pth\n",
      "Finished Training\n",
      "best_valid_loss 0.9207994192838669\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train a LoRA model.\n",
    "\"\"\"\n",
    "\n",
    "best_valid_loss = train_single_model(config)\n",
    "print('best_valid_loss', best_valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09390b84-2b93-469f-8113-f36505a4fa7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights.\n",
      "device cuda:0\n",
      "Total number of parameters: 86100485\n",
      "Number of trainable parameters: 9989\n",
      "Trainable parameters per layer:\n",
      " 9989\n",
      "lora_vit 9989\n",
      "lora_vit.transformer 6144\n",
      "lora_vit.transformer.blocks 6144\n",
      "lora_vit.transformer.blocks.10 3072\n",
      "lora_vit.transformer.blocks.10.attn 3072\n",
      "lora_vit.transformer.blocks.10.attn.proj_q 1536\n",
      "lora_vit.transformer.blocks.10.attn.proj_q.w_a 768\n",
      "lora_vit.transformer.blocks.10.attn.proj_q.w_b 768\n",
      "lora_vit.transformer.blocks.10.attn.proj_v 1536\n",
      "lora_vit.transformer.blocks.10.attn.proj_v.w_a 768\n",
      "lora_vit.transformer.blocks.10.attn.proj_v.w_b 768\n",
      "lora_vit.transformer.blocks.11 3072\n",
      "lora_vit.transformer.blocks.11.attn 3072\n",
      "lora_vit.transformer.blocks.11.attn.proj_q 1536\n",
      "lora_vit.transformer.blocks.11.attn.proj_q.w_a 768\n",
      "lora_vit.transformer.blocks.11.attn.proj_q.w_b 768\n",
      "lora_vit.transformer.blocks.11.attn.proj_v 1536\n",
      "lora_vit.transformer.blocks.11.attn.proj_v.w_a 768\n",
      "lora_vit.transformer.blocks.11.attn.proj_v.w_b 768\n",
      "lora_vit.fc 3845\n",
      "Training Samples - Train 200 Test 512\n",
      "Batch size: 2\n",
      "Fitting Laplace with hessian_structure kron ...\n",
      "Optimizing prior precision ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/CalibratedVisionLoRA/venv/lib/python3.10/site-packages/laplace/baselaplace.py:413: UserWarning: By default `link_approx` is `probit`. Make sure to set it equals to the way you want to call `la(test_data, pred_type=..., link_approx=...)`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Laplace - Done\n",
      "[Baseline] Acc.: 50.8%; ECE: 15.9%; NLL: 0.921\n",
      "[Laplace] Acc.: 51.6%; ECE: 8.3%; NLL: 0.954\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calibration of the trained LoRA model. \n",
    "\"\"\"\n",
    "\n",
    "model_path = '../models/sample_lora_model.pth'\n",
    "\n",
    "config['batch_size'] = 2 \n",
    "config['train_size'] = 200\n",
    "\n",
    "probs_laplace, probs_baseline, targets = \\\n",
    "    fit_laplace_and_compute_predictions(model_path, config, hessian_structure=\"kron\")\n",
    "\n",
    "\n",
    "eval_metrics(probs_baseline, targets, 'Baseline')\n",
    "eval_metrics(probs_laplace, targets, 'Laplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885e2690-bd95-445f-8564-5ce2f2e27ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
